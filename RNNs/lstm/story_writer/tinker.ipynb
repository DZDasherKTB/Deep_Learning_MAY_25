{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d49ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['जीकर', 'भी', 'जी', 'न', 'सके', ',', 'हम', 'तो', 'मर', 'न', 'सके', ',', 'ज़िंदगी', 'से', 'हम', 'प्यार', 'कर', 'न', 'सकें', ',', 'चाहा', 'जिसको', 'हमने', 'वो', ',', 'मिला', 'ही', 'नही', ',', ',', 'ज़िंदगी', 'से', 'हमें', 'ये', 'गिला', 'भी', 'नहीं', ',', 'प्यार', 'क्यूं', 'अब', 'एक', 'सज़ा', 'बन', 'गया', ',', 'रह', 'रह', 'कर', 'ये', 'इक', 'सजा', 'बन', 'गया।', 'हो', 'खुशी', 'चाहें', 'गम', ',', 'सब', 'एक', 'ही', 'मौसम', ',', 'हमनें', 'तो', 'दर्द', 'से', 'नाता', 'ये', 'जोड़', 'लिया', ',', 'ये', 'रिश्ते', 'प्यार', 'के', 'अहसास', 'से', 'बनते', 'हैं', ',', 'लेकिन', 'लोगों', 'ने', 'इन्हे', 'व्यापार', 'समझ', 'लिया।', 'कभी', 'गुब्बारे', 'सा', 'फूट', 'गया', 'था', 'जो', 'मेरा', 'दिल', 'वो', 'अब', 'सुकून', 'पा', 'रहा', 'है', 'कुछ', 'समय', 'बाद', 'ही', 'सही', 'पर', 'तुम्हारा', 'फोन', 'आ', 'रहा', 'है', 'इस', 'खुशी', 'का', 'कैसे', 'जश्न', 'मनाऊं', 'मैं', 'तुम्हारा', 'नाम', 'लेकर', 'ही', 'सुकून', 'आ', 'रहा', 'है', 'आसान', 'नहीं', 'है', 'रास्ता', 'नाम', 'कमाने', 'के', 'लिए', '|', 'अभ्यास', 'करना', 'पड़ता', 'है', 'दर्द', 'मे', 'मुस्कराने', 'के', 'लिए', '|', 'यूँ', 'तो', 'हर', 'दर्द', 'छिपाना', 'चाहता', 'हूं', 'मैं', 'नजरें', 'ही', 'काफी', 'है', 'बताने', 'के', 'लिए', '|', 'ये', 'ज़माना', 'समझता', 'नहीं', 'इशारों', 'की', 'बातो', 'को', 'यहाँ', 'तो', 'फ़रियाद', 'करने', 'के', 'लिए', 'चिल्लाना', 'पड़ता', 'है।', 'बाट', 'जोहते', 'हैं', 'दोऊ', 'नैना', 'काटे', 'से', 'नहीं', 'कटती', 'रैना', 'पिहू', 'मोरे', 'परदेश', 'री', 'सबा', 'मोरासंदेश', 'उन्हेंतू', 'कहना']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def tokenize_line(text):\n",
    "    return re.findall(r'[\\u0900-\\u097F]+|[^\\s\\w]', text, re.UNICODE)\n",
    "\n",
    "data = []\n",
    "with open(\"data/scraped_all.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "tokens = []\n",
    "for entry in data:\n",
    "    for line in entry.get(\"lines\", []):\n",
    "        if line.strip():\n",
    "            tokenss = tokenize_line(line)\n",
    "            for token in tokenss:\n",
    "                tokens.append(token)\n",
    "print(tokens[:200])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15afaba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 7550\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(tokens))\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5542088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 32394, Test size: 8099\n"
     ]
    }
   ],
   "source": [
    "seq_length = 30\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(tokens) - seq_length):\n",
    "    seq = tokens[i:i+seq_length]          # input words\n",
    "    target = tokens[i+seq_length]         # next word to predict\n",
    "    inputs.append([word2idx[w] for w in seq])\n",
    "    targets.append(word2idx[target])\n",
    "\n",
    "import torch\n",
    "\n",
    "X = torch.tensor(inputs) \n",
    "y = torch.tensor(targets) \n",
    "\n",
    "dataset_size = len(X)\n",
    "split_ratio = 0.8\n",
    "split_idx = int(dataset_size * split_ratio)\n",
    "\n",
    "X_train = X[:split_idx]\n",
    "y_train = y[:split_idx]\n",
    "\n",
    "X_test = X[split_idx:]\n",
    "y_test = y[split_idx:]\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6f6dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NextWordRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)   \n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=2, batch_first=True, ) \n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)         \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)    \n",
    "        out, _ = self.lstm(x)     \n",
    "        out = out[:, -1, :]   \n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d2b02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_size = 64\n",
    "hidden_size = 128\n",
    "model = NextWordRNN(vocab_size, embed_size, hidden_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e53e8b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/250, Train Loss: 7.6117, Train Accuracy: 4.18%\n",
      "Epoch 1/250, Test Loss: 7.2890, Test Accuracy: 4.54%\n",
      "Epoch 2/250, Train Loss: 7.0857, Train Accuracy: 5.16%\n",
      "Epoch 2/250, Test Loss: 6.9350, Test Accuracy: 6.07%\n",
      "Epoch 3/250, Train Loss: 6.9364, Train Accuracy: 5.40%\n",
      "Epoch 3/250, Test Loss: 6.8112, Test Accuracy: 6.06%\n",
      "Epoch 4/250, Train Loss: 6.8118, Train Accuracy: 5.69%\n",
      "Epoch 4/250, Test Loss: 6.6949, Test Accuracy: 6.17%\n",
      "Epoch 5/250, Train Loss: 6.6984, Train Accuracy: 5.95%\n",
      "Epoch 5/250, Test Loss: 6.6021, Test Accuracy: 6.56%\n",
      "Epoch 6/250, Train Loss: 6.5902, Train Accuracy: 6.01%\n",
      "Epoch 6/250, Test Loss: 6.4984, Test Accuracy: 6.77%\n",
      "Epoch 7/250, Train Loss: 6.4967, Train Accuracy: 6.15%\n",
      "Epoch 7/250, Test Loss: 6.5233, Test Accuracy: 6.79%\n",
      "Epoch 8/250, Train Loss: 6.4039, Train Accuracy: 6.26%\n",
      "Epoch 8/250, Test Loss: 6.4216, Test Accuracy: 6.83%\n",
      "Epoch 9/250, Train Loss: 6.2969, Train Accuracy: 6.55%\n",
      "Epoch 9/250, Test Loss: 6.3750, Test Accuracy: 6.94%\n",
      "Epoch 10/250, Train Loss: 6.2031, Train Accuracy: 6.85%\n",
      "Epoch 10/250, Test Loss: 6.3347, Test Accuracy: 7.17%\n",
      "Epoch 11/250, Train Loss: 6.1544, Train Accuracy: 6.91%\n",
      "Epoch 11/250, Test Loss: 6.2507, Test Accuracy: 7.33%\n",
      "Epoch 12/250, Train Loss: 6.0501, Train Accuracy: 7.18%\n",
      "Epoch 12/250, Test Loss: 6.1307, Test Accuracy: 7.87%\n",
      "Epoch 13/250, Train Loss: 5.9645, Train Accuracy: 7.51%\n",
      "Epoch 13/250, Test Loss: 6.1102, Test Accuracy: 8.08%\n",
      "Epoch 14/250, Train Loss: 5.8634, Train Accuracy: 7.83%\n",
      "Epoch 14/250, Test Loss: 5.8323, Test Accuracy: 8.68%\n",
      "Epoch 15/250, Train Loss: 5.7691, Train Accuracy: 8.17%\n",
      "Epoch 15/250, Test Loss: 5.8376, Test Accuracy: 8.74%\n",
      "Epoch 16/250, Train Loss: 5.6655, Train Accuracy: 8.46%\n",
      "Epoch 16/250, Test Loss: 5.7340, Test Accuracy: 9.26%\n",
      "Epoch 17/250, Train Loss: 5.5464, Train Accuracy: 8.93%\n",
      "Epoch 17/250, Test Loss: 5.6080, Test Accuracy: 10.01%\n",
      "Epoch 18/250, Train Loss: 5.4384, Train Accuracy: 9.67%\n",
      "Epoch 18/250, Test Loss: 5.4979, Test Accuracy: 10.82%\n",
      "Epoch 19/250, Train Loss: 5.3316, Train Accuracy: 10.28%\n",
      "Epoch 19/250, Test Loss: 5.3833, Test Accuracy: 11.85%\n",
      "Epoch 20/250, Train Loss: 5.2023, Train Accuracy: 11.15%\n",
      "Epoch 20/250, Test Loss: 5.4204, Test Accuracy: 12.32%\n",
      "Epoch 21/250, Train Loss: 5.1029, Train Accuracy: 11.96%\n",
      "Epoch 21/250, Test Loss: 5.2408, Test Accuracy: 14.06%\n",
      "Epoch 22/250, Train Loss: 4.9555, Train Accuracy: 13.33%\n",
      "Epoch 22/250, Test Loss: 5.0657, Test Accuracy: 15.31%\n",
      "Epoch 23/250, Train Loss: 4.8627, Train Accuracy: 14.09%\n",
      "Epoch 23/250, Test Loss: 4.8106, Test Accuracy: 16.97%\n",
      "Epoch 24/250, Train Loss: 4.7625, Train Accuracy: 15.46%\n",
      "Epoch 24/250, Test Loss: 4.6435, Test Accuracy: 18.77%\n",
      "Epoch 25/250, Train Loss: 4.6231, Train Accuracy: 17.35%\n",
      "Epoch 25/250, Test Loss: 4.5376, Test Accuracy: 20.64%\n",
      "Epoch 26/250, Train Loss: 4.5002, Train Accuracy: 19.02%\n",
      "Epoch 26/250, Test Loss: 4.5413, Test Accuracy: 21.58%\n",
      "Epoch 27/250, Train Loss: 4.3783, Train Accuracy: 21.13%\n",
      "Epoch 27/250, Test Loss: 4.3676, Test Accuracy: 23.79%\n",
      "Epoch 28/250, Train Loss: 4.2639, Train Accuracy: 22.63%\n",
      "Epoch 28/250, Test Loss: 4.1259, Test Accuracy: 27.02%\n",
      "Epoch 29/250, Train Loss: 4.1285, Train Accuracy: 24.91%\n",
      "Epoch 29/250, Test Loss: 4.0524, Test Accuracy: 28.21%\n",
      "Epoch 30/250, Train Loss: 3.9913, Train Accuracy: 27.39%\n",
      "Epoch 30/250, Test Loss: 3.9415, Test Accuracy: 29.08%\n",
      "Epoch 31/250, Train Loss: 3.8576, Train Accuracy: 29.23%\n",
      "Epoch 31/250, Test Loss: 3.7292, Test Accuracy: 32.12%\n",
      "Epoch 32/250, Train Loss: 3.7409, Train Accuracy: 31.32%\n",
      "Epoch 32/250, Test Loss: 3.5834, Test Accuracy: 34.46%\n",
      "Epoch 33/250, Train Loss: 3.6303, Train Accuracy: 32.86%\n",
      "Epoch 33/250, Test Loss: 3.4838, Test Accuracy: 35.92%\n",
      "Epoch 34/250, Train Loss: 3.5096, Train Accuracy: 34.96%\n",
      "Epoch 34/250, Test Loss: 3.3354, Test Accuracy: 38.60%\n",
      "Epoch 35/250, Train Loss: 3.3906, Train Accuracy: 36.58%\n",
      "Epoch 35/250, Test Loss: 3.1969, Test Accuracy: 40.39%\n",
      "Epoch 36/250, Train Loss: 3.2643, Train Accuracy: 38.35%\n",
      "Epoch 36/250, Test Loss: 3.0763, Test Accuracy: 41.36%\n",
      "Epoch 37/250, Train Loss: 3.1351, Train Accuracy: 40.72%\n",
      "Epoch 37/250, Test Loss: 2.9679, Test Accuracy: 42.91%\n",
      "Epoch 38/250, Train Loss: 3.0452, Train Accuracy: 41.91%\n",
      "Epoch 38/250, Test Loss: 2.8726, Test Accuracy: 44.66%\n",
      "Epoch 39/250, Train Loss: 2.9522, Train Accuracy: 43.52%\n",
      "Epoch 39/250, Test Loss: 2.8249, Test Accuracy: 44.94%\n",
      "Epoch 40/250, Train Loss: 2.8646, Train Accuracy: 44.89%\n",
      "Epoch 40/250, Test Loss: 2.7181, Test Accuracy: 46.75%\n",
      "Epoch 41/250, Train Loss: 2.7197, Train Accuracy: 47.11%\n",
      "Epoch 41/250, Test Loss: 2.5914, Test Accuracy: 49.20%\n",
      "Epoch 42/250, Train Loss: 2.5998, Train Accuracy: 49.39%\n",
      "Epoch 42/250, Test Loss: 2.4766, Test Accuracy: 50.71%\n",
      "Epoch 43/250, Train Loss: 2.5019, Train Accuracy: 51.04%\n",
      "Epoch 43/250, Test Loss: 2.3670, Test Accuracy: 53.45%\n",
      "Epoch 44/250, Train Loss: 2.4078, Train Accuracy: 52.75%\n",
      "Epoch 44/250, Test Loss: 2.2941, Test Accuracy: 54.50%\n",
      "Epoch 45/250, Train Loss: 2.3149, Train Accuracy: 54.37%\n",
      "Epoch 45/250, Test Loss: 2.2230, Test Accuracy: 55.22%\n",
      "Epoch 46/250, Train Loss: 2.2270, Train Accuracy: 56.07%\n",
      "Epoch 46/250, Test Loss: 2.1203, Test Accuracy: 57.61%\n",
      "Epoch 47/250, Train Loss: 2.1382, Train Accuracy: 57.73%\n",
      "Epoch 47/250, Test Loss: 2.0387, Test Accuracy: 59.44%\n",
      "Epoch 48/250, Train Loss: 2.0598, Train Accuracy: 59.23%\n",
      "Epoch 48/250, Test Loss: 1.9543, Test Accuracy: 61.14%\n",
      "Epoch 49/250, Train Loss: 1.9788, Train Accuracy: 60.68%\n",
      "Epoch 49/250, Test Loss: 1.8950, Test Accuracy: 62.04%\n",
      "Epoch 50/250, Train Loss: 1.8999, Train Accuracy: 62.22%\n",
      "Epoch 50/250, Test Loss: 1.8476, Test Accuracy: 62.64%\n",
      "Epoch 51/250, Train Loss: 1.8200, Train Accuracy: 63.68%\n",
      "Epoch 51/250, Test Loss: 1.7626, Test Accuracy: 64.58%\n",
      "Epoch 52/250, Train Loss: 1.7535, Train Accuracy: 65.27%\n",
      "Epoch 52/250, Test Loss: 1.6949, Test Accuracy: 65.95%\n",
      "Epoch 53/250, Train Loss: 1.6853, Train Accuracy: 66.36%\n",
      "Epoch 53/250, Test Loss: 1.6251, Test Accuracy: 67.37%\n",
      "Epoch 54/250, Train Loss: 1.6197, Train Accuracy: 67.71%\n",
      "Epoch 54/250, Test Loss: 1.5936, Test Accuracy: 67.16%\n",
      "Epoch 55/250, Train Loss: 1.5527, Train Accuracy: 69.19%\n",
      "Epoch 55/250, Test Loss: 1.5024, Test Accuracy: 69.51%\n",
      "Epoch 56/250, Train Loss: 1.4942, Train Accuracy: 70.45%\n",
      "Epoch 56/250, Test Loss: 1.4320, Test Accuracy: 71.77%\n",
      "Epoch 57/250, Train Loss: 1.4455, Train Accuracy: 71.39%\n",
      "Epoch 57/250, Test Loss: 1.4017, Test Accuracy: 71.44%\n",
      "Epoch 58/250, Train Loss: 1.3754, Train Accuracy: 72.86%\n",
      "Epoch 58/250, Test Loss: 1.3515, Test Accuracy: 72.86%\n",
      "Epoch 59/250, Train Loss: 1.3125, Train Accuracy: 74.38%\n",
      "Epoch 59/250, Test Loss: 1.2991, Test Accuracy: 74.14%\n",
      "Epoch 60/250, Train Loss: 1.2519, Train Accuracy: 75.39%\n",
      "Epoch 60/250, Test Loss: 1.2423, Test Accuracy: 75.06%\n",
      "Epoch 61/250, Train Loss: 1.1954, Train Accuracy: 76.91%\n",
      "Epoch 61/250, Test Loss: 1.2154, Test Accuracy: 75.59%\n",
      "Epoch 62/250, Train Loss: 1.1389, Train Accuracy: 77.91%\n",
      "Epoch 62/250, Test Loss: 1.1775, Test Accuracy: 75.94%\n",
      "Epoch 63/250, Train Loss: 1.0877, Train Accuracy: 79.12%\n",
      "Epoch 63/250, Test Loss: 1.1040, Test Accuracy: 77.96%\n",
      "Epoch 64/250, Train Loss: 1.0435, Train Accuracy: 80.05%\n",
      "Epoch 64/250, Test Loss: 1.1431, Test Accuracy: 76.65%\n",
      "Epoch 65/250, Train Loss: 1.0091, Train Accuracy: 80.82%\n",
      "Epoch 65/250, Test Loss: 1.0586, Test Accuracy: 78.71%\n",
      "Epoch 66/250, Train Loss: 0.9592, Train Accuracy: 81.86%\n",
      "Epoch 66/250, Test Loss: 0.9670, Test Accuracy: 81.18%\n",
      "Epoch 67/250, Train Loss: 0.9171, Train Accuracy: 82.74%\n",
      "Epoch 67/250, Test Loss: 0.9009, Test Accuracy: 82.38%\n",
      "Epoch 68/250, Train Loss: 0.8803, Train Accuracy: 83.46%\n",
      "Epoch 68/250, Test Loss: 0.8287, Test Accuracy: 84.17%\n",
      "Epoch 69/250, Train Loss: 0.8560, Train Accuracy: 83.98%\n",
      "Epoch 69/250, Test Loss: 0.7720, Test Accuracy: 85.34%\n",
      "Epoch 70/250, Train Loss: 0.8108, Train Accuracy: 85.01%\n",
      "Epoch 70/250, Test Loss: 0.7271, Test Accuracy: 86.46%\n",
      "Epoch 71/250, Train Loss: 0.7660, Train Accuracy: 85.96%\n",
      "Epoch 71/250, Test Loss: 0.6935, Test Accuracy: 87.32%\n",
      "Epoch 72/250, Train Loss: 0.7235, Train Accuracy: 86.82%\n",
      "Epoch 72/250, Test Loss: 0.6644, Test Accuracy: 87.52%\n",
      "Epoch 73/250, Train Loss: 0.6886, Train Accuracy: 87.83%\n",
      "Epoch 73/250, Test Loss: 0.6643, Test Accuracy: 87.25%\n",
      "Epoch 74/250, Train Loss: 0.6540, Train Accuracy: 88.53%\n",
      "Epoch 74/250, Test Loss: 0.6207, Test Accuracy: 88.46%\n",
      "Epoch 75/250, Train Loss: 0.6203, Train Accuracy: 89.22%\n",
      "Epoch 75/250, Test Loss: 0.6401, Test Accuracy: 87.70%\n",
      "Epoch 76/250, Train Loss: 0.5885, Train Accuracy: 89.98%\n",
      "Epoch 76/250, Test Loss: 0.6300, Test Accuracy: 87.42%\n",
      "Epoch 77/250, Train Loss: 0.5548, Train Accuracy: 90.89%\n",
      "Epoch 77/250, Test Loss: 0.6030, Test Accuracy: 88.68%\n",
      "Epoch 78/250, Train Loss: 0.5179, Train Accuracy: 91.63%\n",
      "Epoch 78/250, Test Loss: 0.5720, Test Accuracy: 89.69%\n",
      "Epoch 79/250, Train Loss: 0.4992, Train Accuracy: 91.93%\n",
      "Epoch 79/250, Test Loss: 0.5722, Test Accuracy: 88.95%\n",
      "Epoch 80/250, Train Loss: 0.4739, Train Accuracy: 92.49%\n",
      "Epoch 80/250, Test Loss: 0.5745, Test Accuracy: 88.43%\n",
      "Epoch 81/250, Train Loss: 0.4515, Train Accuracy: 93.06%\n",
      "Epoch 81/250, Test Loss: 0.6293, Test Accuracy: 87.22%\n",
      "Epoch 82/250, Train Loss: 0.4322, Train Accuracy: 93.35%\n",
      "Epoch 82/250, Test Loss: 0.5591, Test Accuracy: 88.74%\n",
      "Epoch 83/250, Train Loss: 0.4106, Train Accuracy: 93.80%\n",
      "Epoch 83/250, Test Loss: 0.5066, Test Accuracy: 90.39%\n",
      "Epoch 84/250, Train Loss: 0.3877, Train Accuracy: 94.34%\n",
      "Epoch 84/250, Test Loss: 0.4170, Test Accuracy: 92.48%\n",
      "Epoch 85/250, Train Loss: 0.3592, Train Accuracy: 94.97%\n",
      "Epoch 85/250, Test Loss: 0.3724, Test Accuracy: 93.75%\n",
      "Epoch 86/250, Train Loss: 0.3486, Train Accuracy: 95.03%\n",
      "Epoch 86/250, Test Loss: 0.3345, Test Accuracy: 94.52%\n",
      "Epoch 87/250, Train Loss: 0.3236, Train Accuracy: 95.44%\n",
      "Epoch 87/250, Test Loss: 0.3112, Test Accuracy: 95.06%\n",
      "Epoch 88/250, Train Loss: 0.2990, Train Accuracy: 96.15%\n",
      "Epoch 88/250, Test Loss: 0.2854, Test Accuracy: 95.54%\n",
      "Epoch 89/250, Train Loss: 0.2825, Train Accuracy: 96.36%\n",
      "Epoch 89/250, Test Loss: 0.2857, Test Accuracy: 95.31%\n",
      "Epoch 90/250, Train Loss: 0.2690, Train Accuracy: 96.65%\n",
      "Epoch 90/250, Test Loss: 0.2845, Test Accuracy: 95.38%\n",
      "Epoch 91/250, Train Loss: 0.2566, Train Accuracy: 96.92%\n",
      "Epoch 91/250, Test Loss: 0.2949, Test Accuracy: 95.07%\n",
      "Epoch 92/250, Train Loss: 0.2443, Train Accuracy: 96.97%\n",
      "Epoch 92/250, Test Loss: 0.2555, Test Accuracy: 95.75%\n",
      "Epoch 93/250, Train Loss: 0.2339, Train Accuracy: 97.27%\n",
      "Epoch 93/250, Test Loss: 0.2465, Test Accuracy: 96.21%\n",
      "Epoch 94/250, Train Loss: 0.2277, Train Accuracy: 97.26%\n",
      "Epoch 94/250, Test Loss: 0.2226, Test Accuracy: 96.37%\n",
      "Epoch 95/250, Train Loss: 0.2173, Train Accuracy: 97.42%\n",
      "Epoch 95/250, Test Loss: 0.1797, Test Accuracy: 97.49%\n",
      "Epoch 96/250, Train Loss: 0.2024, Train Accuracy: 97.66%\n",
      "Epoch 96/250, Test Loss: 0.1648, Test Accuracy: 97.88%\n",
      "Epoch 97/250, Train Loss: 0.1924, Train Accuracy: 97.96%\n",
      "Epoch 97/250, Test Loss: 0.1653, Test Accuracy: 97.73%\n",
      "Epoch 98/250, Train Loss: 0.1799, Train Accuracy: 98.05%\n",
      "Epoch 98/250, Test Loss: 0.1491, Test Accuracy: 98.18%\n",
      "Epoch 99/250, Train Loss: 0.1672, Train Accuracy: 98.29%\n",
      "Epoch 99/250, Test Loss: 0.1443, Test Accuracy: 98.05%\n",
      "Epoch 100/250, Train Loss: 0.1619, Train Accuracy: 98.39%\n",
      "Epoch 100/250, Test Loss: 0.1348, Test Accuracy: 98.21%\n",
      "Epoch 101/250, Train Loss: 0.1494, Train Accuracy: 98.57%\n",
      "Epoch 101/250, Test Loss: 0.1459, Test Accuracy: 98.14%\n",
      "Epoch 102/250, Train Loss: 0.1459, Train Accuracy: 98.58%\n",
      "Epoch 102/250, Test Loss: 0.1289, Test Accuracy: 98.42%\n",
      "Epoch 103/250, Train Loss: 0.1471, Train Accuracy: 98.46%\n",
      "Epoch 103/250, Test Loss: 0.1244, Test Accuracy: 98.22%\n",
      "Epoch 104/250, Train Loss: 0.1364, Train Accuracy: 98.63%\n",
      "Epoch 104/250, Test Loss: 0.1281, Test Accuracy: 98.00%\n",
      "Epoch 105/250, Train Loss: 0.1301, Train Accuracy: 98.68%\n",
      "Epoch 105/250, Test Loss: 0.1308, Test Accuracy: 97.90%\n",
      "Epoch 106/250, Train Loss: 0.1223, Train Accuracy: 98.81%\n",
      "Epoch 106/250, Test Loss: 0.1122, Test Accuracy: 98.38%\n",
      "Epoch 107/250, Train Loss: 0.1218, Train Accuracy: 98.78%\n",
      "Epoch 107/250, Test Loss: 0.1174, Test Accuracy: 98.36%\n",
      "Epoch 108/250, Train Loss: 0.1186, Train Accuracy: 98.84%\n",
      "Epoch 108/250, Test Loss: 0.1156, Test Accuracy: 98.17%\n",
      "Epoch 109/250, Train Loss: 0.1184, Train Accuracy: 98.69%\n",
      "Epoch 109/250, Test Loss: 0.1447, Test Accuracy: 97.89%\n",
      "Epoch 110/250, Train Loss: 0.1148, Train Accuracy: 98.84%\n",
      "Epoch 110/250, Test Loss: 0.1325, Test Accuracy: 97.75%\n",
      "Epoch 111/250, Train Loss: 0.1076, Train Accuracy: 98.97%\n",
      "Epoch 111/250, Test Loss: 0.1219, Test Accuracy: 98.04%\n",
      "Epoch 112/250, Train Loss: 0.1043, Train Accuracy: 98.87%\n",
      "Epoch 112/250, Test Loss: 0.1274, Test Accuracy: 97.88%\n",
      "Epoch 113/250, Train Loss: 0.1047, Train Accuracy: 98.86%\n",
      "Epoch 113/250, Test Loss: 0.1176, Test Accuracy: 97.88%\n",
      "Epoch 114/250, Train Loss: 0.1013, Train Accuracy: 98.90%\n",
      "Epoch 114/250, Test Loss: 0.1121, Test Accuracy: 97.96%\n",
      "Epoch 115/250, Train Loss: 0.1098, Train Accuracy: 98.74%\n",
      "Epoch 115/250, Test Loss: 0.1207, Test Accuracy: 97.90%\n",
      "Epoch 116/250, Train Loss: 0.1118, Train Accuracy: 98.68%\n",
      "Epoch 116/250, Test Loss: 0.0937, Test Accuracy: 98.65%\n",
      "Epoch 117/250, Train Loss: 0.1061, Train Accuracy: 98.74%\n",
      "Epoch 117/250, Test Loss: 0.0818, Test Accuracy: 98.85%\n",
      "Epoch 118/250, Train Loss: 0.0913, Train Accuracy: 99.01%\n",
      "Epoch 118/250, Test Loss: 0.0770, Test Accuracy: 98.90%\n",
      "Epoch 119/250, Train Loss: 0.0803, Train Accuracy: 99.26%\n",
      "Epoch 119/250, Test Loss: 0.0646, Test Accuracy: 99.12%\n",
      "Epoch 120/250, Train Loss: 0.0752, Train Accuracy: 99.31%\n",
      "Epoch 120/250, Test Loss: 0.0734, Test Accuracy: 99.05%\n",
      "Epoch 121/250, Train Loss: 0.0735, Train Accuracy: 99.31%\n",
      "Epoch 121/250, Test Loss: 0.0812, Test Accuracy: 98.64%\n",
      "Epoch 122/250, Train Loss: 0.0751, Train Accuracy: 99.28%\n",
      "Epoch 122/250, Test Loss: 0.0842, Test Accuracy: 98.68%\n",
      "Epoch 123/250, Train Loss: 0.0821, Train Accuracy: 99.09%\n",
      "Epoch 123/250, Test Loss: 0.1032, Test Accuracy: 98.20%\n",
      "Epoch 124/250, Train Loss: 0.1016, Train Accuracy: 98.58%\n",
      "Epoch 124/250, Test Loss: 0.1238, Test Accuracy: 97.47%\n",
      "Epoch 125/250, Train Loss: 0.1172, Train Accuracy: 98.18%\n",
      "Epoch 125/250, Test Loss: 0.1131, Test Accuracy: 97.79%\n",
      "Epoch 126/250, Train Loss: 0.1231, Train Accuracy: 97.89%\n",
      "Epoch 126/250, Test Loss: 0.0978, Test Accuracy: 98.25%\n",
      "Epoch 127/250, Train Loss: 0.1056, Train Accuracy: 98.40%\n",
      "Epoch 127/250, Test Loss: 0.0679, Test Accuracy: 99.07%\n",
      "Epoch 128/250, Train Loss: 0.0740, Train Accuracy: 99.16%\n",
      "Epoch 128/250, Test Loss: 0.0506, Test Accuracy: 99.30%\n",
      "Epoch 129/250, Train Loss: 0.0542, Train Accuracy: 99.54%\n",
      "Epoch 129/250, Test Loss: 0.0403, Test Accuracy: 99.51%\n",
      "Epoch 130/250, Train Loss: 0.0431, Train Accuracy: 99.73%\n",
      "Epoch 130/250, Test Loss: 0.0306, Test Accuracy: 99.73%\n",
      "Epoch 131/250, Train Loss: 0.0354, Train Accuracy: 99.79%\n",
      "Epoch 131/250, Test Loss: 0.0352, Test Accuracy: 99.62%\n",
      "Epoch 132/250, Train Loss: 0.0312, Train Accuracy: 99.84%\n",
      "Epoch 132/250, Test Loss: 0.0327, Test Accuracy: 99.57%\n",
      "Epoch 133/250, Train Loss: 0.0304, Train Accuracy: 99.86%\n",
      "Epoch 133/250, Test Loss: 0.0385, Test Accuracy: 99.58%\n",
      "Epoch 134/250, Train Loss: 0.0327, Train Accuracy: 99.80%\n",
      "Epoch 134/250, Test Loss: 0.0715, Test Accuracy: 98.74%\n",
      "Epoch 135/250, Train Loss: 0.0667, Train Accuracy: 99.02%\n",
      "Epoch 135/250, Test Loss: 0.1676, Test Accuracy: 96.33%\n",
      "Epoch 136/250, Train Loss: 0.2130, Train Accuracy: 94.94%\n",
      "Epoch 136/250, Test Loss: 0.2051, Test Accuracy: 95.01%\n",
      "Epoch 137/250, Train Loss: 0.2506, Train Accuracy: 93.68%\n",
      "Epoch 137/250, Test Loss: 0.1126, Test Accuracy: 97.62%\n",
      "Epoch 138/250, Train Loss: 0.1489, Train Accuracy: 96.91%\n",
      "Epoch 138/250, Test Loss: 0.0516, Test Accuracy: 99.30%\n",
      "Epoch 139/250, Train Loss: 0.0672, Train Accuracy: 99.17%\n",
      "Epoch 139/250, Test Loss: 0.0289, Test Accuracy: 99.73%\n",
      "Epoch 140/250, Train Loss: 0.0358, Train Accuracy: 99.81%\n",
      "Epoch 140/250, Test Loss: 0.0215, Test Accuracy: 99.86%\n",
      "Epoch 141/250, Train Loss: 0.0227, Train Accuracy: 99.93%\n",
      "Epoch 141/250, Test Loss: 0.0181, Test Accuracy: 99.94%\n",
      "Epoch 142/250, Train Loss: 0.0173, Train Accuracy: 99.95%\n",
      "Epoch 142/250, Test Loss: 0.0155, Test Accuracy: 99.91%\n",
      "Epoch 143/250, Train Loss: 0.0145, Train Accuracy: 99.96%\n",
      "Epoch 143/250, Test Loss: 0.0141, Test Accuracy: 99.93%\n",
      "Epoch 144/250, Train Loss: 0.0128, Train Accuracy: 99.96%\n",
      "Epoch 144/250, Test Loss: 0.0149, Test Accuracy: 99.88%\n",
      "Epoch 145/250, Train Loss: 0.0120, Train Accuracy: 99.96%\n",
      "Epoch 145/250, Test Loss: 0.0153, Test Accuracy: 99.88%\n",
      "Epoch 146/250, Train Loss: 0.0111, Train Accuracy: 99.95%\n",
      "Epoch 146/250, Test Loss: 0.0176, Test Accuracy: 99.79%\n",
      "Epoch 147/250, Train Loss: 0.0147, Train Accuracy: 99.92%\n",
      "Epoch 147/250, Test Loss: 0.0264, Test Accuracy: 99.58%\n",
      "Epoch 148/250, Train Loss: 0.0333, Train Accuracy: 99.62%\n",
      "Epoch 148/250, Test Loss: 0.1844, Test Accuracy: 95.64%\n",
      "Epoch 149/250, Train Loss: 0.3097, Train Accuracy: 91.71%\n",
      "Epoch 149/250, Test Loss: 0.2820, Test Accuracy: 92.69%\n",
      "Epoch 150/250, Train Loss: 0.3575, Train Accuracy: 90.61%\n",
      "Epoch 150/250, Test Loss: 0.1177, Test Accuracy: 97.57%\n",
      "Epoch 151/250, Train Loss: 0.1500, Train Accuracy: 96.73%\n",
      "Epoch 151/250, Test Loss: 0.0554, Test Accuracy: 99.14%\n",
      "Epoch 152/250, Train Loss: 0.0605, Train Accuracy: 99.19%\n",
      "Epoch 152/250, Test Loss: 0.0278, Test Accuracy: 99.78%\n",
      "Epoch 153/250, Train Loss: 0.0291, Train Accuracy: 99.86%\n",
      "Epoch 153/250, Test Loss: 0.0177, Test Accuracy: 99.89%\n",
      "Epoch 154/250, Train Loss: 0.0194, Train Accuracy: 99.94%\n",
      "Epoch 154/250, Test Loss: 0.0137, Test Accuracy: 99.96%\n",
      "Epoch 155/250, Train Loss: 0.0150, Train Accuracy: 99.95%\n",
      "Epoch 155/250, Test Loss: 0.0121, Test Accuracy: 99.96%\n",
      "Epoch 156/250, Train Loss: 0.0125, Train Accuracy: 99.95%\n",
      "Epoch 156/250, Test Loss: 0.0114, Test Accuracy: 99.96%\n",
      "Epoch 157/250, Train Loss: 0.0109, Train Accuracy: 99.96%\n",
      "Epoch 157/250, Test Loss: 0.0099, Test Accuracy: 99.96%\n",
      "Epoch 158/250, Train Loss: 0.0098, Train Accuracy: 99.95%\n",
      "Epoch 158/250, Test Loss: 0.0087, Test Accuracy: 99.96%\n",
      "Epoch 159/250, Train Loss: 0.0087, Train Accuracy: 99.96%\n",
      "Epoch 159/250, Test Loss: 0.0081, Test Accuracy: 99.96%\n",
      "Epoch 160/250, Train Loss: 0.0085, Train Accuracy: 99.95%\n",
      "Epoch 160/250, Test Loss: 0.0078, Test Accuracy: 99.96%\n",
      "Epoch 161/250, Train Loss: 0.0075, Train Accuracy: 99.96%\n",
      "Epoch 161/250, Test Loss: 0.0075, Test Accuracy: 99.94%\n",
      "Epoch 162/250, Train Loss: 0.0069, Train Accuracy: 99.95%\n",
      "Epoch 162/250, Test Loss: 0.0117, Test Accuracy: 99.84%\n",
      "Epoch 163/250, Train Loss: 0.0080, Train Accuracy: 99.93%\n",
      "Epoch 163/250, Test Loss: 0.0351, Test Accuracy: 99.42%\n",
      "Epoch 164/250, Train Loss: 0.2668, Train Accuracy: 93.03%\n",
      "Epoch 164/250, Test Loss: 0.4251, Test Accuracy: 89.71%\n",
      "Epoch 165/250, Train Loss: 0.4917, Train Accuracy: 86.64%\n",
      "Epoch 165/250, Test Loss: 0.1514, Test Accuracy: 96.33%\n",
      "Epoch 166/250, Train Loss: 0.2154, Train Accuracy: 94.42%\n",
      "Epoch 166/250, Test Loss: 0.0564, Test Accuracy: 99.16%\n",
      "Epoch 167/250, Train Loss: 0.0766, Train Accuracy: 98.75%\n",
      "Epoch 167/250, Test Loss: 0.0266, Test Accuracy: 99.84%\n",
      "Epoch 168/250, Train Loss: 0.0342, Train Accuracy: 99.81%\n",
      "Epoch 168/250, Test Loss: 0.0153, Test Accuracy: 99.95%\n",
      "Epoch 169/250, Train Loss: 0.0208, Train Accuracy: 99.94%\n",
      "Epoch 169/250, Test Loss: 0.0117, Test Accuracy: 99.96%\n",
      "Epoch 170/250, Train Loss: 0.0157, Train Accuracy: 99.95%\n",
      "Epoch 170/250, Test Loss: 0.0097, Test Accuracy: 99.96%\n",
      "Epoch 171/250, Train Loss: 0.0129, Train Accuracy: 99.95%\n",
      "Epoch 171/250, Test Loss: 0.0086, Test Accuracy: 99.96%\n",
      "Epoch 172/250, Train Loss: 0.0109, Train Accuracy: 99.95%\n",
      "Epoch 172/250, Test Loss: 0.0077, Test Accuracy: 99.96%\n",
      "Epoch 173/250, Train Loss: 0.0094, Train Accuracy: 99.96%\n",
      "Epoch 173/250, Test Loss: 0.0069, Test Accuracy: 99.96%\n",
      "Epoch 174/250, Train Loss: 0.0082, Train Accuracy: 99.96%\n",
      "Epoch 174/250, Test Loss: 0.0063, Test Accuracy: 99.96%\n",
      "Epoch 175/250, Train Loss: 0.0073, Train Accuracy: 99.96%\n",
      "Epoch 175/250, Test Loss: 0.0061, Test Accuracy: 99.96%\n",
      "Epoch 176/250, Train Loss: 0.0065, Train Accuracy: 99.96%\n",
      "Epoch 176/250, Test Loss: 0.0055, Test Accuracy: 99.96%\n",
      "Epoch 177/250, Train Loss: 0.0059, Train Accuracy: 99.96%\n",
      "Epoch 177/250, Test Loss: 0.0050, Test Accuracy: 99.96%\n",
      "Epoch 178/250, Train Loss: 0.0053, Train Accuracy: 99.96%\n",
      "Epoch 178/250, Test Loss: 0.0045, Test Accuracy: 99.96%\n",
      "Epoch 179/250, Train Loss: 0.0050, Train Accuracy: 99.96%\n",
      "Epoch 179/250, Test Loss: 0.0044, Test Accuracy: 99.96%\n",
      "Epoch 180/250, Train Loss: 0.0046, Train Accuracy: 99.96%\n",
      "Epoch 180/250, Test Loss: 0.0040, Test Accuracy: 99.96%\n",
      "Epoch 181/250, Train Loss: 0.0061, Train Accuracy: 99.95%\n",
      "Epoch 181/250, Test Loss: 0.0111, Test Accuracy: 99.83%\n",
      "Epoch 182/250, Train Loss: 0.2926, Train Accuracy: 92.36%\n",
      "Epoch 182/250, Test Loss: 0.5301, Test Accuracy: 86.59%\n",
      "Epoch 183/250, Train Loss: 0.5700, Train Accuracy: 84.72%\n",
      "Epoch 183/250, Test Loss: 0.1271, Test Accuracy: 96.89%\n",
      "Epoch 184/250, Train Loss: 0.2244, Train Accuracy: 94.03%\n",
      "Epoch 184/250, Test Loss: 0.0489, Test Accuracy: 99.26%\n",
      "Epoch 185/250, Train Loss: 0.0775, Train Accuracy: 98.63%\n",
      "Epoch 185/250, Test Loss: 0.0235, Test Accuracy: 99.84%\n",
      "Epoch 186/250, Train Loss: 0.0344, Train Accuracy: 99.75%\n",
      "Epoch 186/250, Test Loss: 0.0145, Test Accuracy: 99.93%\n",
      "Epoch 187/250, Train Loss: 0.0199, Train Accuracy: 99.91%\n",
      "Epoch 187/250, Test Loss: 0.0106, Test Accuracy: 99.95%\n",
      "Epoch 188/250, Train Loss: 0.0143, Train Accuracy: 99.95%\n",
      "Epoch 188/250, Test Loss: 0.0087, Test Accuracy: 99.96%\n",
      "Epoch 189/250, Train Loss: 0.0115, Train Accuracy: 99.95%\n",
      "Epoch 189/250, Test Loss: 0.0075, Test Accuracy: 99.96%\n",
      "Epoch 190/250, Train Loss: 0.0097, Train Accuracy: 99.95%\n",
      "Epoch 190/250, Test Loss: 0.0067, Test Accuracy: 99.96%\n",
      "Epoch 191/250, Train Loss: 0.0083, Train Accuracy: 99.95%\n",
      "Epoch 191/250, Test Loss: 0.0059, Test Accuracy: 99.96%\n",
      "Epoch 192/250, Train Loss: 0.0073, Train Accuracy: 99.96%\n",
      "Epoch 192/250, Test Loss: 0.0054, Test Accuracy: 99.96%\n",
      "Epoch 193/250, Train Loss: 0.0066, Train Accuracy: 99.95%\n",
      "Epoch 193/250, Test Loss: 0.0049, Test Accuracy: 99.96%\n",
      "Epoch 194/250, Train Loss: 0.0059, Train Accuracy: 99.95%\n",
      "Epoch 194/250, Test Loss: 0.0044, Test Accuracy: 99.96%\n",
      "Epoch 195/250, Train Loss: 0.0052, Train Accuracy: 99.95%\n",
      "Epoch 195/250, Test Loss: 0.0041, Test Accuracy: 99.96%\n",
      "Epoch 196/250, Train Loss: 0.0048, Train Accuracy: 99.95%\n",
      "Epoch 196/250, Test Loss: 0.0038, Test Accuracy: 99.96%\n",
      "Epoch 197/250, Train Loss: 0.0044, Train Accuracy: 99.96%\n",
      "Epoch 197/250, Test Loss: 0.0038, Test Accuracy: 99.96%\n",
      "Epoch 198/250, Train Loss: 0.0041, Train Accuracy: 99.96%\n",
      "Epoch 198/250, Test Loss: 0.0038, Test Accuracy: 99.96%\n",
      "Epoch 199/250, Train Loss: 0.0044, Train Accuracy: 99.95%\n",
      "Epoch 199/250, Test Loss: 0.0088, Test Accuracy: 99.90%\n",
      "Epoch 200/250, Train Loss: 0.0653, Train Accuracy: 98.36%\n",
      "Epoch 200/250, Test Loss: 0.7164, Test Accuracy: 82.48%\n",
      "Epoch 201/250, Train Loss: 0.6094, Train Accuracy: 83.96%\n",
      "Epoch 201/250, Test Loss: 0.2301, Test Accuracy: 93.95%\n",
      "Epoch 202/250, Train Loss: 0.3231, Train Accuracy: 91.29%\n",
      "Epoch 202/250, Test Loss: 0.0745, Test Accuracy: 98.21%\n",
      "Epoch 203/250, Train Loss: 0.1077, Train Accuracy: 97.59%\n",
      "Epoch 203/250, Test Loss: 0.0289, Test Accuracy: 99.72%\n",
      "Epoch 204/250, Train Loss: 0.0394, Train Accuracy: 99.60%\n",
      "Epoch 204/250, Test Loss: 0.0177, Test Accuracy: 99.79%\n",
      "Epoch 205/250, Train Loss: 0.0207, Train Accuracy: 99.90%\n",
      "Epoch 205/250, Test Loss: 0.0117, Test Accuracy: 99.94%\n",
      "Epoch 206/250, Train Loss: 0.0142, Train Accuracy: 99.94%\n",
      "Epoch 206/250, Test Loss: 0.0086, Test Accuracy: 99.96%\n",
      "Epoch 207/250, Train Loss: 0.0113, Train Accuracy: 99.95%\n",
      "Epoch 207/250, Test Loss: 0.0075, Test Accuracy: 99.96%\n",
      "Epoch 208/250, Train Loss: 0.0114, Train Accuracy: 99.93%\n",
      "Epoch 208/250, Test Loss: 0.0079, Test Accuracy: 99.95%\n",
      "Epoch 209/250, Train Loss: 0.0085, Train Accuracy: 99.95%\n",
      "Epoch 209/250, Test Loss: 0.0058, Test Accuracy: 99.96%\n",
      "Epoch 210/250, Train Loss: 0.0070, Train Accuracy: 99.96%\n",
      "Epoch 210/250, Test Loss: 0.0052, Test Accuracy: 99.96%\n",
      "Epoch 211/250, Train Loss: 0.0061, Train Accuracy: 99.95%\n",
      "Epoch 211/250, Test Loss: 0.0047, Test Accuracy: 99.96%\n",
      "Epoch 212/250, Train Loss: 0.0054, Train Accuracy: 99.96%\n",
      "Epoch 212/250, Test Loss: 0.0044, Test Accuracy: 99.96%\n",
      "Epoch 213/250, Train Loss: 0.0049, Train Accuracy: 99.96%\n",
      "Epoch 213/250, Test Loss: 0.0039, Test Accuracy: 99.96%\n",
      "Epoch 214/250, Train Loss: 0.0044, Train Accuracy: 99.96%\n",
      "Epoch 214/250, Test Loss: 0.0037, Test Accuracy: 99.96%\n",
      "Epoch 215/250, Train Loss: 0.0039, Train Accuracy: 99.96%\n",
      "Epoch 215/250, Test Loss: 0.0034, Test Accuracy: 99.96%\n",
      "Epoch 216/250, Train Loss: 0.0036, Train Accuracy: 99.96%\n",
      "Epoch 216/250, Test Loss: 0.0031, Test Accuracy: 99.96%\n",
      "Epoch 217/250, Train Loss: 0.0033, Train Accuracy: 99.96%\n",
      "Epoch 217/250, Test Loss: 0.0028, Test Accuracy: 99.96%\n",
      "Epoch 218/250, Train Loss: 0.0034, Train Accuracy: 99.96%\n",
      "Epoch 218/250, Test Loss: 0.0026, Test Accuracy: 99.96%\n",
      "Epoch 219/250, Train Loss: 0.0041, Train Accuracy: 99.96%\n",
      "Epoch 219/250, Test Loss: 0.0047, Test Accuracy: 99.90%\n",
      "Epoch 220/250, Train Loss: 0.2619, Train Accuracy: 93.09%\n",
      "Epoch 220/250, Test Loss: 0.4685, Test Accuracy: 87.86%\n",
      "Epoch 221/250, Train Loss: 0.5406, Train Accuracy: 85.32%\n",
      "Epoch 221/250, Test Loss: 0.1127, Test Accuracy: 97.18%\n",
      "Epoch 222/250, Train Loss: 0.2216, Train Accuracy: 94.06%\n",
      "Epoch 222/250, Test Loss: 0.0386, Test Accuracy: 99.41%\n",
      "Epoch 223/250, Train Loss: 0.0714, Train Accuracy: 98.65%\n",
      "Epoch 223/250, Test Loss: 0.0154, Test Accuracy: 99.94%\n",
      "Epoch 224/250, Train Loss: 0.0288, Train Accuracy: 99.74%\n",
      "Epoch 224/250, Test Loss: 0.0107, Test Accuracy: 99.94%\n",
      "Epoch 225/250, Train Loss: 0.0161, Train Accuracy: 99.92%\n",
      "Epoch 225/250, Test Loss: 0.0084, Test Accuracy: 99.95%\n",
      "Epoch 226/250, Train Loss: 0.0112, Train Accuracy: 99.95%\n",
      "Epoch 226/250, Test Loss: 0.0066, Test Accuracy: 99.96%\n",
      "Epoch 227/250, Train Loss: 0.0091, Train Accuracy: 99.95%\n",
      "Epoch 227/250, Test Loss: 0.0058, Test Accuracy: 99.96%\n",
      "Epoch 228/250, Train Loss: 0.0076, Train Accuracy: 99.95%\n",
      "Epoch 228/250, Test Loss: 0.0051, Test Accuracy: 99.96%\n",
      "Epoch 229/250, Train Loss: 0.0066, Train Accuracy: 99.95%\n",
      "Epoch 229/250, Test Loss: 0.0046, Test Accuracy: 99.96%\n",
      "Epoch 230/250, Train Loss: 0.0058, Train Accuracy: 99.95%\n",
      "Epoch 230/250, Test Loss: 0.0041, Test Accuracy: 99.96%\n",
      "Epoch 231/250, Train Loss: 0.0051, Train Accuracy: 99.95%\n",
      "Epoch 231/250, Test Loss: 0.0038, Test Accuracy: 99.96%\n",
      "Epoch 232/250, Train Loss: 0.0046, Train Accuracy: 99.96%\n",
      "Epoch 232/250, Test Loss: 0.0035, Test Accuracy: 99.96%\n",
      "Epoch 233/250, Train Loss: 0.0041, Train Accuracy: 99.96%\n",
      "Epoch 233/250, Test Loss: 0.0033, Test Accuracy: 99.96%\n",
      "Epoch 234/250, Train Loss: 0.0038, Train Accuracy: 99.96%\n",
      "Epoch 234/250, Test Loss: 0.0032, Test Accuracy: 99.96%\n",
      "Epoch 235/250, Train Loss: 0.0035, Train Accuracy: 99.96%\n",
      "Epoch 235/250, Test Loss: 0.0028, Test Accuracy: 99.96%\n",
      "Epoch 236/250, Train Loss: 0.0033, Train Accuracy: 99.96%\n",
      "Epoch 236/250, Test Loss: 0.0026, Test Accuracy: 99.96%\n",
      "Epoch 237/250, Train Loss: 0.0031, Train Accuracy: 99.96%\n",
      "Epoch 237/250, Test Loss: 0.0030, Test Accuracy: 99.96%\n",
      "Epoch 238/250, Train Loss: 0.0033, Train Accuracy: 99.95%\n",
      "Epoch 238/250, Test Loss: 0.0097, Test Accuracy: 99.84%\n",
      "Epoch 239/250, Train Loss: 0.2250, Train Accuracy: 94.01%\n",
      "Epoch 239/250, Test Loss: 0.3891, Test Accuracy: 89.67%\n",
      "Epoch 240/250, Train Loss: 0.5179, Train Accuracy: 85.88%\n",
      "Epoch 240/250, Test Loss: 0.1187, Test Accuracy: 96.83%\n",
      "Epoch 241/250, Train Loss: 0.2310, Train Accuracy: 93.70%\n",
      "Epoch 241/250, Test Loss: 0.0321, Test Accuracy: 99.53%\n",
      "Epoch 242/250, Train Loss: 0.0762, Train Accuracy: 98.38%\n",
      "Epoch 242/250, Test Loss: 0.0143, Test Accuracy: 99.93%\n",
      "Epoch 243/250, Train Loss: 0.0288, Train Accuracy: 99.70%\n",
      "Epoch 243/250, Test Loss: 0.0088, Test Accuracy: 99.96%\n",
      "Epoch 244/250, Train Loss: 0.0151, Train Accuracy: 99.92%\n",
      "Epoch 244/250, Test Loss: 0.0070, Test Accuracy: 99.96%\n",
      "Epoch 245/250, Train Loss: 0.0104, Train Accuracy: 99.94%\n",
      "Epoch 245/250, Test Loss: 0.0059, Test Accuracy: 99.96%\n",
      "Epoch 246/250, Train Loss: 0.0083, Train Accuracy: 99.94%\n",
      "Epoch 246/250, Test Loss: 0.0052, Test Accuracy: 99.96%\n",
      "Epoch 247/250, Train Loss: 0.0070, Train Accuracy: 99.95%\n",
      "Epoch 247/250, Test Loss: 0.0047, Test Accuracy: 99.96%\n",
      "Epoch 248/250, Train Loss: 0.0061, Train Accuracy: 99.95%\n",
      "Epoch 248/250, Test Loss: 0.0043, Test Accuracy: 99.96%\n",
      "Epoch 249/250, Train Loss: 0.0054, Train Accuracy: 99.95%\n",
      "Epoch 249/250, Test Loss: 0.0040, Test Accuracy: 99.96%\n",
      "Epoch 250/250, Train Loss: 0.0048, Train Accuracy: 99.95%\n",
      "Epoch 250/250, Test Loss: 0.0036, Test Accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "num_epochs = 250\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        xb = X[i:i+batch_size].to(device)\n",
    "        yb = y[i:i+batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, dim=1) \n",
    "        correct += (predicted == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    avg_train_loss = epoch_loss / (len(X) // batch_size)\n",
    "    train_accuracy = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # --- Testing / Validation ---\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            xb = X_test[i:i+batch_size].to(device)\n",
    "            yb = y_test[i:i+batch_size].to(device)\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct_test += (predicted == yb).sum().item()\n",
    "            total_test += yb.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / (len(X_test) // batch_size)\n",
    "    test_accuracy = correct_test / total_test * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c1705f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"next_word.pth\")\n",
    "import pickle\n",
    "with open(\"word2idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word2idx, f)\n",
    "with open(\"idx2word.pkl\", \"wb\") as f:\n",
    "    pickle.dump(idx2word, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50368d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, prompt, k=3):\n",
    "    model.eval()\n",
    "    prompt_tokens = re.findall(r'[\\u0900-\\u097F]+|[^\\s\\w]', prompt, re.UNICODE)\n",
    "    input_seq = prompt_tokens[-seq_length:]\n",
    "    input_ids = [word2idx.get(w, 0) for w in input_seq]\n",
    "    input_tensor = torch.tensor([input_ids]).to(next(model.parameters()).device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)                \n",
    "        probs = torch.softmax(output, dim=1)         # probabilities\n",
    "        top_probs, top_indices = torch.topk(probs, k)\n",
    "\n",
    "        predictions = [idx2word[idx.item()] for idx in top_indices[0]]\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c1c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c3bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
