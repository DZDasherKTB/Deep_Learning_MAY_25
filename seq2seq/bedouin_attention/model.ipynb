{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca2d5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7700cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 724\n",
      "Example sentence: ['the quick brown fox jumps over the lazy dog', 'my mum tries to be cool by saying that she likes all the same things that i do']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "with open(\"data/data.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    "text = text.lower()  \n",
    "\n",
    "sentences = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "\n",
    "print(f\"Number of sentences: {len(sentences)}\")\n",
    "print(f\"Example sentence: {sentences[0:2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "220efd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example pair:\n",
      "('he decided to fake his disappearance to avoid jail', 'eh dediced ot ekaf sih ecnaraeppasid ot diova liaj')\n",
      "Vocabulary size: 5208\n",
      "Sample words with indices: [('001', 2), ('005', 3), ('01', 4), ('1', 5), ('10', 6), ('100', 7), ('1111', 8), ('1234', 9), ('17thcentury', 10), ('18', 11)]\n"
     ]
    }
   ],
   "source": [
    "def reverse_words_in_sentence(sentence):\n",
    "    return \" \".join(word[::-1] for word in sentence.split())\n",
    "pairs = [(s, reverse_words_in_sentence(s)) for s in sentences]\n",
    "print(\"Example pair:\")\n",
    "print(random.choice(pairs))\n",
    "\n",
    "all_words = set()\n",
    "for inp, out in pairs:\n",
    "    all_words.update(inp.split())\n",
    "    all_words.update(out.split())\n",
    "word_list = sorted(all_words)\n",
    "\n",
    "word2idx = {w: i+2 for i, w in enumerate(word_list)}  # reserve 0 and 1 for special tokens\n",
    "word2idx['<pad>'] = 0\n",
    "word2idx['<unk>'] = 1\n",
    "word2idx['<sos>'] = len(word2idx)\n",
    "word2idx['<eos>'] = len(word2idx)\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "print(f\"Vocabulary size: {len(word2idx)}\")\n",
    "print(\"Sample words with indices:\", list(word2idx.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33b9a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices: [4428, 3262, 335, 1698, 2319, 3044, 4428, 2453, 1028]\n",
      "Recovered: the quick brown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_indices(sentence, word2idx):\n",
    "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
    "\n",
    "def indices_to_sentence(indices, idx2word):\n",
    "    return ' '.join(idx2word.get(idx, '<unk>') for idx in indices)\n",
    "\n",
    "sample_sentence = pairs[0][0]\n",
    "indices = sentence_to_indices(sample_sentence, word2idx)\n",
    "print(\"Indices:\", indices)\n",
    "\n",
    "recovered_sentence = indices_to_sentence(indices, idx2word)\n",
    "print(\"Recovered:\", recovered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09283f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseWordsDataset(Dataset):\n",
    "    def __init__(self, pairs, word2idx):\n",
    "        self.pairs = pairs\n",
    "        self.word2idx = word2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp_sentence, out_sentence = self.pairs[idx]\n",
    "        inp_indices = [self.word2idx.get(w, self.word2idx['<unk>']) for w in inp_sentence.split()]\n",
    "        \n",
    "        # Add <sos> and <eos> to target\n",
    "        out_indices = [self.word2idx['<sos>']] + [self.word2idx.get(w, self.word2idx['<unk>']) for w in out_sentence.split()] + [self.word2idx['<eos>']]\n",
    "        \n",
    "        return torch.tensor(inp_indices, dtype=torch.long), torch.tensor(out_indices, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15294089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # batch is list of tuples (input_tensor, output_tensor)\n",
    "    inputs, outputs = zip(*batch)\n",
    "\n",
    "    # Pad sequences to the max length in the batch (padding value = 0 for <pad>)\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    outputs_padded = pad_sequence(outputs, batch_first=True, padding_value=0)\n",
    "\n",
    "    return inputs_padded, outputs_padded\n",
    "\n",
    "dataset = ReverseWordsDataset(pairs, word2idx)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21636ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)  # [batch, src_len, emb_dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden  # [n_layers, batch, hid_dim]\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.unsqueeze(1)  # [batch_size, 1]\n",
    "        embedded = self.embedding(input)  # [batch_size, 1, emb_dim]\n",
    "        output, hidden = self.rnn(embedded, hidden)  # output: [batch_size, 1, hid_dim]\n",
    "        prediction = self.fc_out(output.squeeze(1))  # [batch_size, output_dim]\n",
    "        return prediction, hidden\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        hidden = self.encoder(src)\n",
    "        input = trg[:, 0]  # First token (<sos>)\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            input = trg[:, t] if teacher_force else output.argmax(1)\n",
    "\n",
    "        return outputs\n",
    "    def translate(self, src_tensor, max_len, sos_idx, eos_idx):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            hidden = self.encoder(src_tensor)  # [n_layers, batch, hid_dim]\n",
    "            input_token = torch.LongTensor([sos_idx]).to(self.device)  # start token\n",
    "\n",
    "            translated_tokens = [sos_idx]\n",
    "\n",
    "            for _ in range(max_len):\n",
    "                output, hidden = self.decoder(input_token, hidden)  # output shape: [batch_size=1, output_dim]\n",
    "                pred_token = output.argmax(1).item()\n",
    "                translated_tokens.append(pred_token)\n",
    "\n",
    "                if pred_token == eos_idx:\n",
    "                    break\n",
    "\n",
    "                input_token = torch.LongTensor([pred_token]).to(self.device)\n",
    "\n",
    "            return translated_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26609e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(word2idx)\n",
    "OUTPUT_DIM = len(word2idx)\n",
    "\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "PAD_IDX = word2idx['<pad>']\n",
    "print(PAD_IDX)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71929a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 3s\n",
      "\tTrain Loss: 4.242\n",
      "\t Val. Loss: 4.194\n",
      "Epoch: 02 | Time: 0m 2s\n",
      "\tTrain Loss: 3.968\n",
      "\t Val. Loss: 3.995\n",
      "Epoch: 03 | Time: 0m 3s\n",
      "\tTrain Loss: 3.661\n",
      "\t Val. Loss: 3.684\n",
      "Epoch: 04 | Time: 0m 3s\n",
      "\tTrain Loss: 3.426\n",
      "\t Val. Loss: 3.414\n",
      "Epoch: 05 | Time: 0m 4s\n",
      "\tTrain Loss: 3.130\n",
      "\t Val. Loss: 3.076\n",
      "Epoch: 06 | Time: 0m 4s\n",
      "\tTrain Loss: 2.779\n",
      "\t Val. Loss: 2.808\n",
      "Epoch: 07 | Time: 0m 3s\n",
      "\tTrain Loss: 2.424\n",
      "\t Val. Loss: 2.541\n",
      "Epoch: 08 | Time: 0m 3s\n",
      "\tTrain Loss: 2.103\n",
      "\t Val. Loss: 2.215\n",
      "Epoch: 09 | Time: 0m 4s\n",
      "\tTrain Loss: 1.771\n",
      "\t Val. Loss: 1.848\n",
      "Epoch: 10 | Time: 0m 3s\n",
      "\tTrain Loss: 1.442\n",
      "\t Val. Loss: 1.537\n",
      "Epoch: 11 | Time: 0m 3s\n",
      "\tTrain Loss: 1.176\n",
      "\t Val. Loss: 1.155\n",
      "Epoch: 12 | Time: 0m 4s\n",
      "\tTrain Loss: 0.932\n",
      "\t Val. Loss: 0.843\n",
      "Epoch: 13 | Time: 0m 4s\n",
      "\tTrain Loss: 0.691\n",
      "\t Val. Loss: 0.584\n",
      "Epoch: 14 | Time: 0m 3s\n",
      "\tTrain Loss: 0.480\n",
      "\t Val. Loss: 0.401\n",
      "Epoch: 15 | Time: 0m 3s\n",
      "\tTrain Loss: 0.348\n",
      "\t Val. Loss: 0.278\n",
      "Epoch: 16 | Time: 0m 3s\n",
      "\tTrain Loss: 0.246\n",
      "\t Val. Loss: 0.201\n",
      "Epoch: 17 | Time: 0m 4s\n",
      "\tTrain Loss: 0.184\n",
      "\t Val. Loss: 0.155\n",
      "Epoch: 18 | Time: 0m 3s\n",
      "\tTrain Loss: 0.142\n",
      "\t Val. Loss: 0.116\n",
      "Epoch: 19 | Time: 0m 3s\n",
      "\tTrain Loss: 0.113\n",
      "\t Val. Loss: 0.096\n",
      "Epoch: 20 | Time: 0m 3s\n",
      "\tTrain Loss: 0.094\n",
      "\t Val. Loss: 0.082\n",
      "Epoch: 21 | Time: 0m 4s\n",
      "\tTrain Loss: 0.080\n",
      "\t Val. Loss: 0.071\n",
      "Epoch: 22 | Time: 0m 4s\n",
      "\tTrain Loss: 0.070\n",
      "\t Val. Loss: 0.062\n",
      "Epoch: 23 | Time: 0m 2s\n",
      "\tTrain Loss: 0.061\n",
      "\t Val. Loss: 0.055\n",
      "Epoch: 24 | Time: 0m 2s\n",
      "\tTrain Loss: 0.055\n",
      "\t Val. Loss: 0.050\n",
      "Epoch: 25 | Time: 0m 2s\n",
      "\tTrain Loss: 0.049\n",
      "\t Val. Loss: 0.045\n",
      "Epoch: 26 | Time: 0m 2s\n",
      "\tTrain Loss: 0.045\n",
      "\t Val. Loss: 0.041\n",
      "Epoch: 27 | Time: 0m 2s\n",
      "\tTrain Loss: 0.041\n",
      "\t Val. Loss: 0.038\n",
      "Epoch: 28 | Time: 0m 2s\n",
      "\tTrain Loss: 0.037\n",
      "\t Val. Loss: 0.034\n",
      "Epoch: 29 | Time: 0m 2s\n",
      "\tTrain Loss: 0.034\n",
      "\t Val. Loss: 0.032\n",
      "Epoch: 30 | Time: 0m 2s\n",
      "\tTrain Loss: 0.032\n",
      "\t Val. Loss: 0.030\n",
      "Epoch: 31 | Time: 0m 2s\n",
      "\tTrain Loss: 0.029\n",
      "\t Val. Loss: 0.028\n",
      "Epoch: 32 | Time: 0m 2s\n",
      "\tTrain Loss: 0.027\n",
      "\t Val. Loss: 0.026\n",
      "Epoch: 33 | Time: 0m 2s\n",
      "\tTrain Loss: 0.026\n",
      "\t Val. Loss: 0.024\n",
      "Epoch: 34 | Time: 0m 2s\n",
      "\tTrain Loss: 0.024\n",
      "\t Val. Loss: 0.023\n",
      "Epoch: 35 | Time: 0m 2s\n",
      "\tTrain Loss: 0.023\n",
      "\t Val. Loss: 0.021\n",
      "Epoch: 36 | Time: 0m 2s\n",
      "\tTrain Loss: 0.021\n",
      "\t Val. Loss: 0.020\n",
      "Epoch: 37 | Time: 0m 2s\n",
      "\tTrain Loss: 0.020\n",
      "\t Val. Loss: 0.019\n",
      "Epoch: 38 | Time: 0m 2s\n",
      "\tTrain Loss: 0.019\n",
      "\t Val. Loss: 0.018\n",
      "Epoch: 39 | Time: 0m 2s\n",
      "\tTrain Loss: 0.018\n",
      "\t Val. Loss: 0.017\n",
      "Epoch: 40 | Time: 0m 2s\n",
      "\tTrain Loss: 0.017\n",
      "\t Val. Loss: 0.016\n",
      "Epoch: 41 | Time: 0m 2s\n",
      "\tTrain Loss: 0.016\n",
      "\t Val. Loss: 0.015\n",
      "Epoch: 42 | Time: 0m 2s\n",
      "\tTrain Loss: 0.015\n",
      "\t Val. Loss: 0.015\n",
      "Epoch: 43 | Time: 0m 2s\n",
      "\tTrain Loss: 0.015\n",
      "\t Val. Loss: 0.014\n",
      "Epoch: 44 | Time: 0m 2s\n",
      "\tTrain Loss: 0.014\n",
      "\t Val. Loss: 0.013\n",
      "Epoch: 45 | Time: 0m 2s\n",
      "\tTrain Loss: 0.013\n",
      "\t Val. Loss: 0.013\n",
      "Epoch: 46 | Time: 0m 2s\n",
      "\tTrain Loss: 0.013\n",
      "\t Val. Loss: 0.012\n",
      "Epoch: 47 | Time: 0m 2s\n",
      "\tTrain Loss: 0.012\n",
      "\t Val. Loss: 0.012\n",
      "Epoch: 48 | Time: 0m 2s\n",
      "\tTrain Loss: 0.012\n",
      "\t Val. Loss: 0.011\n",
      "Epoch: 49 | Time: 0m 2s\n",
      "\tTrain Loss: 0.011\n",
      "\t Val. Loss: 0.011\n",
      "Epoch: 50 | Time: 0m 2s\n",
      "\tTrain Loss: 0.011\n",
      "\t Val. Loss: 0.011\n",
      "Epoch: 51 | Time: 0m 2s\n",
      "\tTrain Loss: 0.010\n",
      "\t Val. Loss: 0.010\n",
      "Epoch: 52 | Time: 0m 2s\n",
      "\tTrain Loss: 0.010\n",
      "\t Val. Loss: 0.010\n",
      "Epoch: 53 | Time: 0m 2s\n",
      "\tTrain Loss: 0.010\n",
      "\t Val. Loss: 0.009\n",
      "Epoch: 54 | Time: 0m 2s\n",
      "\tTrain Loss: 0.009\n",
      "\t Val. Loss: 0.009\n",
      "Epoch: 55 | Time: 0m 2s\n",
      "\tTrain Loss: 0.009\n",
      "\t Val. Loss: 0.009\n",
      "Epoch: 56 | Time: 0m 2s\n",
      "\tTrain Loss: 0.009\n",
      "\t Val. Loss: 0.008\n",
      "Epoch: 57 | Time: 0m 2s\n",
      "\tTrain Loss: 0.008\n",
      "\t Val. Loss: 0.008\n",
      "Epoch: 58 | Time: 0m 2s\n",
      "\tTrain Loss: 0.008\n",
      "\t Val. Loss: 0.008\n",
      "Epoch: 59 | Time: 0m 2s\n",
      "\tTrain Loss: 0.008\n",
      "\t Val. Loss: 0.008\n",
      "Epoch: 60 | Time: 0m 2s\n",
      "\tTrain Loss: 0.008\n",
      "\t Val. Loss: 0.007\n",
      "Epoch: 61 | Time: 0m 2s\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.007\n",
      "Epoch: 62 | Time: 0m 2s\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.007\n",
      "Epoch: 63 | Time: 0m 2s\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.007\n",
      "Epoch: 64 | Time: 0m 2s\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.006\n",
      "Epoch: 65 | Time: 0m 2s\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.006\n",
      "Epoch: 66 | Time: 0m 2s\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.006\n",
      "Epoch: 67 | Time: 0m 2s\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.006\n",
      "Epoch: 68 | Time: 0m 2s\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.006\n",
      "Epoch: 69 | Time: 0m 2s\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.006\n",
      "Epoch: 70 | Time: 0m 2s\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 71 | Time: 0m 2s\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 72 | Time: 0m 2s\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 73 | Time: 0m 2s\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 74 | Time: 0m 2s\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 75 | Time: 0m 2s\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 76 | Time: 0m 2s\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 77 | Time: 0m 2s\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.005\n",
      "Epoch: 78 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 79 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 80 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 81 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 82 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 83 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 84 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 85 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 86 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 87 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.004\n",
      "Epoch: 88 | Time: 0m 2s\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 89 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 90 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 91 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 92 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 93 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 94 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 95 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 96 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 97 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 98 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 99 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n",
      "Epoch: 100 | Time: 0m 2s\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, device, clip=1.0):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, trg in dataloader:\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio=0.5)  # output shape: (batch_size, trg_len, vocab_size)\n",
    "\n",
    "        # Skip the first token (<sos>) for loss calculation\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)  # (batch_size * (trg_len-1), vocab_size)\n",
    "        trg = trg[:, 1:].reshape(-1)  # (batch_size * (trg_len-1))\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)  # no teacher forcing during evaluation\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, dataloader, optimizer, criterion, device)\n",
    "    valid_loss = evaluate(model, dataloader, criterion, device)  # using same data as validation\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = divmod(int(end_time - start_time), 60)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98cb9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, word2idx, idx2word, device, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = sentence.lower().split()\n",
    "    src_indices = [word2idx.get(token, word2idx['<unk>']) for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    trg_indexes = model.translate(src_tensor, max_len, word2idx['<sos>'], word2idx['<eos>'])\n",
    "    translated_tokens = [idx2word[i] for i in trg_indexes[1:-1]]  # skip <sos> and <eos>\n",
    "\n",
    "    return ' '.join(translated_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bee87cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated sentence: yffulf yffulf sesu segdew sesu sesu sesu sââãnosrep yrneh egaruoc ti\n"
     ]
    }
   ],
   "source": [
    "# Suppose you have a source sentence as a list of tokens (words):\n",
    "src_sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
    "\n",
    "# Convert it to indices using your word2idx dictionary\n",
    "src_indexes = [word2idx.get(tok, word2idx['<unk>']) for tok in src_sentence]\n",
    "\n",
    "# Add batch dimension (1, seq_len) and convert to tensor\n",
    "src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)  # shape: [1, seq_len]\n",
    "\n",
    "max_len = 50  # maximum length of translation output\n",
    "sos_idx = word2idx['<sos>']\n",
    "eos_idx = word2idx['<eos>']\n",
    "\n",
    "# Call translate\n",
    "translated_indices = model.translate(src_tensor, max_len, sos_idx, eos_idx)\n",
    "\n",
    "# Convert indices back to words (ignoring sos and eos tokens)\n",
    "translated_words = [idx2word[idx] for idx in translated_indices if idx not in (sos_idx, eos_idx)]\n",
    "\n",
    "print(\"Translated sentence:\", ' '.join(translated_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a34db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
